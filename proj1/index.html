<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Lena Jeon, Kevin Ponce, CS184</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>Give a high-level overview of what you implemented in this project. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the project.</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
  <h4 align="middle">Walk through how you rasterize triangles in your own words.</h4>
  <p>In this part, we rasterized the triangles by utilizing the line test we went over in lecture. 
    More specifically, our algorithm goes line by line, uses the line test to see if that sample lies 
    within the triangle or not, and stops checking that line once it sees a sample that’s no longer in the triangle. 
    Then it moves onto the next line, and so on until all the lines that make up the triangle have been checked.</p>
  <h4 align="middle">Explain how your algorithm is no worse than one that checks each sample within the bounding box of the triangle.</h4>
  <p>Our algorithm is no worse than one that checks every sample in the triangle’s bounding box because it won’t ever check every single pixel in the bounding box. 
    I think this is easier to demonstrate with a picture: see below.</p>
    
    <div align="middle">
      <table style="width=100%">
        <tr>
          <td>
            <img src="images/Untitled-1.png" align="middle" width="600px"/>
            <figcaption align="middle">This algorithm performs the same as the “check all samples” algorithm if the triangle is a 90-degree triangle with its 90-degree corner situated right at the upper right corner. 
             In which case all samples will be checked, since we’re sweeping from left to right. 
             But it performs no worse because it won’t ever check samples twice.</figcaption>
          </td>
        </tr>
      </table>
    </div>
                    
  <h4 align="middle">Show a png screenshot of basic/test4.svg with the default viewing parameters and with the pixel inspector centered on an interesting part of the scene.</h4>
    <p>I don’t understand what part of this scene of colored triangles would qualify as “interesting”, so I took two screenshots just in case our tastes differ.</p>
    
    <div align="middle">
      <table style="width=100%">
        <tr>
          <td>
            <img src="images/screenshot_2-6_19-8-48.png" align="middle" width="800px"/>
            <figcaption align="middle">basic/test4.svg with default viewing params.</figcaption>
          </td>
          </tr>
        <br>
        <tr>
          <td>
            <img src="images/screenshot_2-6_19-9-8.png" align="middle" width="400px"/>
            <figcaption align="middle">Point of interest(?) #1: Green, upper-right triangle, bottom left corner.</figcaption>
          </td>
        </tr>
        <br>
        <tr>
       		<td>
            <img src="images/screenshot_2-6_19-9-13.png" align="middle" width="400px"/>
            <figcaption align="middle">Point of interest(?) #2: Red, middle triangle, very right corner (kinda broken). 
              (I mean, people often say broken things are interesting, so…)</figcaption>
          </td>
        </tr>
      </table>
    </div>
    
<p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/image1.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="images/image2.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/image3.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/image4.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
  </table>
</div>


<h3 align="middle">Part 2: Antialiasing triangles</h3>
<h4 align="middle">Walk through your supersampling algorithm and data structures. Why is supersampling useful? What modifications did you make to the rasterization pipeline in the process? Explain how you used supersampling to antialias your triangles.</h4>

	<p>For our implementation of supersampling, we increased my sample buffer in set_sample_rate, artificially increasing the image's resolution (regarding how we sample the image). Then, in rasterize_triangle we multiiplied x and y by the square root of the sample rate--since the sample rate tells us how many samples we're taking in a box, the number of samples we're taking along the x and y increase by the square root.</p> 

	<p>We then set up the triangle's bounding box by picking the minimum and maximum x and y from these artificially blown-up points and looped through the triangle's bounding box as normal. One key change was made to the fill_pixel function, to have y also be multiplied by the square root of the sample rate to reflect the artificially-enlarged canvas we were "drawing" from.</p>

	<p>Next, after taking these samples, we averaged the color values for each pixel in resolve_to_framebuffer. Inside of the already-existing double for loop, we put another nested double for loop to check the samples we'd gathered for each individual pixel. These samples are the very same ones we'd just put into the sample buffer. Pixel by pixel, we'd total all the data we'd collected together, then averaged them out according to the number of samples we'd collected (i.e. the sample rate). This value was then passed into the rgb_framebuffer_target like in the previous part, to be used to draw our now nicely super-sampled triangle. </p>

<h4 align="middle">Show png screenshots of basic/test4.svg with the default viewing parameters and sample rates 1, 4, and 16 to compare them side-by-side. Position the pixel inspector over an area that showcases the effect dramatically; for example, a very skinny triangle corner.</h4>
	
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/part2-1.png" align="middle" width="800px"/>
        <figcaption align="middle">Default viewing parameters.</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/part2-2.png" align="middle" width="800px"/>
        <figcaption align="middle">Sample rate = 4.</figcaption>
      </td>
    </tr>
    <tr>
      <td>
        <img src="images/part2-3.png" align="middle" width="800px"/>
        <figcaption align="middle">Sample rate = 16.</figcaption>
      </td>
    </tr>
  </table>
</div>

<h4 align="middle">Explain why these results are observed.</h4>

	<p>We see these results (the triangles becoming "smoother") because increasing the sample rate means that we have more pieces of data to use in assembling our representation of our original image. When our sample rate is 1, that means that for each pixel, we're only taking in the data at one part of the original image, and using that data to dictate the color of the pixel. This effectively works as a binary of sorts, telling us if the pixel we're looking at is, for example, red or white in the case of the red triangle pictured in the first image. </p>

	<p>However, if we increase our sample rate, we don't need to limit ourselves to just being red or white: instead, we can look at the average of all our values sampled (or supersampled if you will) to create the illusion of a smoother edge. Anti-aliasing effectively places semi-transparent, or "blended" pixels, along the border of an otherwise sharp edge to fool the eye into filling in the blanks more naturally. </p>


<h3 align="middle">Part 3: Transforms</h3>
<h4 align="middle">Create an updated version of svg/transforms/robot.svg with cubeman doing something more interesting, 
  like waving or running. Feel free to change his colors or proportions to suit your creativity. 
  Save your svg file as my_robot.svg in your docs/ directory and show a png screenshot of your rendered drawing in your write-up. 
  Explain what you were trying to do with cubeman in words.</h4>

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/screenshot_2-6_20-8-26.png" align="middle" width="600px"/>
        </td>
      </tr>
    </table>
  </div>
  
  <p><a href="https://youtu.be/NUqPyj7L714?t=38">"Talk is cheap,"</a> so here is a picture explaining what I tried to do instead:</p>
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/ryu.png" align="middle" width="117px"/>
        </td>
      </tr>
    </table>
  </div>
  
  <p>I used Illustrator to pose the robot to my fancy, then copy/pasted those new values for the transforms of each of the shapes into the original robot svg file. I know one could go into the SVG file and hand-alter the values one-by-one as well, but that's not as fun. </p>

  <p>(Cubeman's red is also based on the color of Ryu's headband: it's slightly different from the default.)</p>


<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>

<h4 align="middle">Explain barycentric coordinates in your own words and use an image to aid you in your explanation. One idea is to use a svg file that plots a single triangle with one red, one green, and one blue vertex, which should produce a smoothly blended color triangle.</h4>

<p> While I don't have an svg file with a single triangle to show (strapped for time, haha), I did find a picture online. </p>

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="https://codeplea.com/public/content/tri-int-bary.png" align="middle" width="277px"/>
          <figcaption align="middle"><a href="https://codeplea.com/triangular-interpolation">"Source"</a></figcaption>
        </td>
      </tr>
    </table>
</div>

<p>(Trust me, we implemented barycentric coordinates properly. Check the next image.)</p>

<p>Barycentric coordinates are a way of reckoning space by using the three points of a triangle. By recording your position from the three points as a percentage or fraction of how close you are to said points, all the points within a triangle can be accounted for as functions of the three points.</p>

<p>In other words, if you look at the image above, the closer you are to the green vertex, V2, the greener you are, the closer you are to the red vertex the redder you are, and so on. By reckoning space in this manner, we're able to calculate a smooth gradient of color as seen above: the reason we get a gradient is because we can alter the color values at each position as being equal to their percent distance to each of the vertex. A point that's got a value of 100% on V2, for instance, will have 0% V1 and 0% V2, making it take on 100% of V2's color. Another example is to take a point near the middle of the triangle: say this point is 33% of the way to V2, 33% of the way to V1, and 34% of the way to V3. This point will then take on a color value that is 33% of V1's color, 33% of V2's color, and 34% of V3's, resulting in the brownish hue we get in the middle of the triangle.</p>

<p>Barycentric coordinates can be calculated by creating normals that pass through each of the vertices, like miniature axes (plural of axis). For instance, in the above picture, a point that lies on the line between V1 and V3 would have a V2 value of 0%, and the closer one travels to V2, the higher the V2 value gets. This scaling allows us to have nicely colored triangles, regardless of the triangle's shape.</p>


<h4 align="middle">Show a png screenshot of svg/basic/test7.svg with default viewing parameters and sample rate 1. If you make any additional images with color gradients, include them.</h4>

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/part4.png" align="middle" width="800px"/>
        </td>
      </tr>
    </table>
</div>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>

<h4 align="middle">Explain pixel sampling in your own words and describe how you implemented it to perform texture mapping. Briefly discuss the two different pixel sampling methods, nearest and bilinear.</h4>

<p>Here, pixel sampling was us taking values from a texture and applying them to digital space (in the form of a triangle). We operated between two planes, the digital one and the texture one, and to figure out what color each pixel should be, we'd look at the corresponding values stored in our texture. In both cases, we implemented clamps to ensure that the texels we were sampling were in bounds.</p>

<p>I feel pixel sampling has already been described in the supersampling section, so I'll talk about the changes between that scenario and this one. Because we're working with texture maps, instead of having some solid color that we paint into our pixels and have to blend with supersamples, we instead determine our pixels' colors via the texture map, and have to blend our pixels according to the pixels on that texture map. How we blend or color these pixels depends on our sampling method.</p>

<p>Nearest sampling is exactly what it sounds like: given a point (u,v), we'd find the pixel location that is is closest to it, consult what that value is on our texture, and then return that value. Nearest sampling commonly produces a sharp edge for this reason, and is very common for upscaling pixel art.</p>

<p>Bilinear sampling, on the other hand, is a bit more complicated. Given a point (u,v), to try and make a "smoother" image, we do something similar to the interpolation performed in the previous part. We'd first find four pixels that encompassed (u,v) best in a box-like formation. Then, by calculating how close (u,v) was to the edges of the four pixels we'd chosen, we could weigh the values of each of these four points by lerping them, first horizontally, then vertically. By doing this, we'd be able to render our image a bit more smoothly (less jaggies) by creating transitional effects between what would otherwise be sharp edges. Bilinear's smoothness generally makes it better than nearest for photo-realistic images, though it can cause images to get blurry at the cost of reducing jaggies.</p>

<h4 align="middle">Check out the svg files in the svg/texmap/ directory. Use the pixel inspector to find a good example of where bilinear sampling clearly defeats nearest sampling. Show and compare four png screenshots using nearest sampling at 1 sample per pixel, nearest sampling at 16 samples per pixel, bilinear sampling at 1 sample per pixel, and bilinear sampling at 16 samples per pixel. </h4>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/part5-1.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest, 1 sample per pixel.</figcaption>
      </td>
      <td>
        <img src="images/part5-2.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest, 16 samples per pixel.</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/part5-3.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear, 1 sample per pixel.</figcaption>
      </td>
      <td>
        <img src="images/part5-4.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear, 16 samples per pixel.</figcaption>
      </td>
    </tr>
  </table>
</div>


<h4 align="middle">Comment on the relative differences. Discuss when there will be a large difference between the two methods and why.</h4>

<p>In this image, we can see that the equator line is a lot smoother in the renders that use bilinear sampling versus nearest: in nearest, the line comes off as rather chunky, whereas bilinear smoothes it out. Additionally, the white latitudinal lines are rather jagged and sharp in the nearest render, whereas the bilinear's algorithm allows for those lines to look more curved, enhancing the beveled quality of the image.</p> 


<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>



<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
